{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zSWEG5PCsMB"
      },
      "source": [
        "## **Práctica 1: Introducción a TensorFlow / Keras**\n",
        "\n",
        "<hr>\n",
        "\n",
        "El objetivo de esta práctica es aprender a configurar un entorno de trabajo para el bloque 2 de la asignatura Visión Artificial, utilizando **Visual Studio Code**, **Jupyter Notebook**, **Conda** y **TensorFlow**.\n",
        "\n",
        "**Visual Studio Code** (VS Code) es un editor de código fuente desarrollado por Microsoft. Es gratuito, de código abierto, multiplataforma y es conocido por su ligereza y rapidez. Además es altamente personalizable gracias a su amplia gama de extensiones. Nosotros lo personalizaremos para ejecutar **Python** y **Notebooks Jupyter**.\n",
        "\n",
        "**Jupyter Notebook** es una herramienta interactiva que permite crear y compartir documentos que contienen código ejecutable, texto explicativo, ecuaciones, visualizaciones y más. Es ideal para el aprendizaje, la experimentación y el desarrollo de proyectos en inteligencia artificial y ciencia de datos. Sus principales ventajas incluyen:\n",
        "- Integración de código y texto explicativo en un único documento.\n",
        "- Visualización interactiva de datos.\n",
        "- Fácil de compartir y reproducir.\n",
        "\n",
        "**Conda** es un gestor de paquetes y entornos que facilita la instalación de dependencias y la creación de entornos virtuales aislados. Esto te permite:\n",
        "- Evitar conflictos entre paquetes.\n",
        "- Mantener tus proyectos organizados y con configuraciones específicas.\n",
        "\n",
        "**TensorFlow** es un framework que facilita la creación, el entrenamiento y la exportación de modelos de aprendizaje automático de manera eficiente. Las versiones de TensorFlow 2.X incorporan **Keras** como su API principal para la construcción de modelos de aprendizaje profundo. Esto simplifica el desarrollo, ofreciendo:\n",
        "- Una sintaxis más intuitiva y modular.\n",
        "- Ejecución por defecto en modo *eager*, lo que facilita la depuración.\n",
        "- Soporte optimizado para CPU, GPU y TPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEIAkAybFQ_B"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### **1. Configuración del entorno**\n",
        "\n",
        "Para trabajar con Python y Jupyter Notebook en VSCode, es necesario instalar sus extensiones. Aquí tienes los pasos para hacerlo, asumiendo que tienes abierto este fichero en VSCode:\n",
        "\n",
        "1. Haz clic en el icono de extensiones en la barra lateral izquierda.\n",
        "2. En la barra de búsqueda, escribe \"Python\" y selecciona la extensión desarrollada por Microsoft.\n",
        "3. Haz clic en el botón de \"Instalar\" para añadir la extensión a tu VS Code.\n",
        "4. Repite los pasos 2 y 3 escribiendo \"Jupyter\".\n",
        "\n",
        "A continuación, deberás crear un entorno virtual con Conda. En los ordenadores de prácticas de la Universidad ya está instalado **Anaconda** y **Python**, por lo que no es necesario instalar nada. Aquí tienes los pasos a seguir:\n",
        "1. Abre el menú de inicio de Windows.\n",
        "2. Busca y ejecuta la aplicación **Anaconda Prompt** (Consola de Anaconda). Desde esta consola, podrás activar el entorno, instalar dependencias y ejecutar Jupyter Notebook.\n",
        "3. Crea un nuevo entorno con: `conda create --name VA2 python=3.10`. Esto configurará un entorno llamado `VA2` con Python 3.10.\n",
        "4. Activa el entorno con: `conda activate VA2`.\n",
        "5. Instala una librería: `pip install ipykernel`.\n",
        "6. Puedes desactivar el entorno con: `conda deactivate`.\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <strong>NOTA:</strong> En tu ordenador personal tendrás que instalar <i>Anaconda</i> si no lo tenías previamente. Más información: https://www.anaconda.com/download\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <strong>NOTA:</strong> Si en tu ordenador personal utilizas Linux o MacOS, deberás abrir un Terminal para ejecutar los pasos 3 a 6.\n",
        "</div>\n",
        "\n",
        "Para ejecutar este Notebook en el entorno que acabas de crear desde VSCode tendrás que hacer clic en la esquina superior derecha donde dice _Select Kernel_ y elegir el entorno ``VA2``. Por último, ejecuta el siguiente bloque de código para verificar que el entorno creado funciona correctamente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oHIZZTBJQPV"
      },
      "outputs": [],
      "source": [
        "print(\"¡Funciona!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7tg75UoKUdR"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### **2. Instalación de TensorFlow y otras librerías**\n",
        "\n",
        "Para instalar TensorFlow en el entorno de trabajo creado, puedes hacerlo ejecutando de nuevo la aplicación Anaconda Prompt, activando el entorno ``VA2`` e instalando la librería: `pip install tensorflow`.\n",
        "\n",
        "Sin embargo, es posible instalar librerías directamente desde un Notebook. Para ello, basta utilizar el signo de exclamación (`!`) al inicio de un bloque de código, lo que indica que el comando debe ejecutarse en la terminal en lugar de interpretarse como código Python.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCDDEXfLKTzk"
      },
      "outputs": [],
      "source": [
        "! pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m3Oxgp8HLmH"
      },
      "source": [
        "Además de TensorFlow, utilizaremos otras librerías que definiremos e instalaremos a continuación.\n",
        "\n",
        "**Pandas** está considerada la librería más popular de análisis de datos en Python y maneja todas sus operaciones mediante un objeto \"Dataframe\". Para instalarla:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Up-F62kHhEV"
      },
      "outputs": [],
      "source": [
        "! pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlaGXsGxJYTr"
      },
      "source": [
        "**Matplotlib** es una librería que permite realizar una gran variedad de gráficos. Para instalarla:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLjhSZxbHuR3"
      },
      "outputs": [],
      "source": [
        "! pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQmu7ICdJnud"
      },
      "source": [
        "**OpenCV** es la principal librería de programación destinada a tareas de visión por computador. Para instalarla:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt_FLLNyIDYW"
      },
      "outputs": [],
      "source": [
        "! pip install opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6YNB1yIKQYC"
      },
      "source": [
        "**SciPy** es una librería Python utilizada para computación científica, matemáticas, ciencias e ingeniería."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QISNPnlWID8m"
      },
      "outputs": [],
      "source": [
        "! pip install scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaYPmL-NKQ2a"
      },
      "source": [
        "**Scikit-learn** es una librería Python para el desarrollo de modelos de aprendizaje automático."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzdvA7chHLIQ"
      },
      "outputs": [],
      "source": [
        "! pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZOYfSvkDdHd"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## ANEXO\n",
        "\n",
        "En este anexo se presenta un resumen con las principales funciones y métodos de TensorFlow que utilizaremos en la asignatura. Estas herramientas nos permitirán construir, entrenar y evaluar modelos de aprendizaje automático de manera eficiente.\n",
        "\n",
        "Para más información y detalles, puedes consultar la documentación oficial de TensorFlow: https://www.tensorflow.org/api_docs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ex6p43REjdl"
      },
      "source": [
        "<hr>\n",
        "\n",
        "#### Capas\n",
        "\n",
        "*  `tensorflow.keras.layers.Activation(activation)`: Applies an activation function to an output.\n",
        "    *  `activation`: Activation function to use. If None, no activation is applied. Possible values: 'relu', 'sigmoid', 'softmax', etc.\n",
        "\n",
        "*  `tensorflow.keras.layers.AveragePooling2D()`: Average pooling operation for 2D spatial data.\n",
        "\n",
        "*  `tensorflow.keras.layers.BatchNormalization()`: Layer that normalizes its inputs.\n",
        "\n",
        "*  `tensorflow.keras.layers.Concatenate()`: Concatenates a list of inputs.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "Concatenate()([x1, x2])\n",
        "\n",
        "```\n",
        "\n",
        "*  `tensorflow.keras.layers.Conv2D(filters, kernel_size, strides=(1, 1),padding='valid', activation=None, use_bias=True)`: 2D convolution layer.\n",
        "    *  `filters`: Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
        "    *  `kernel_size`: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n",
        "    *  `strides`: An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions.\n",
        "    *  `padding`: one of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input. When padding=\"same\" and strides=1, the output has the same size as the input.\n",
        "    *  `activation`: Activation function to use. If None, no activation is applied. Possible values: 'relu', 'sigmoid', 'softmax', etc.\n",
        "    *  `use_bias`: Boolean, whether the layer uses a bias vector.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "Conv2D(16, 5, activation='relu', input_shape=(64,64,1))\n",
        "\n",
        "```\n",
        "\n",
        "* `tensorflow.keras.layers.Conv2DTranspose(filters, kernel_size, strides=(1, 1), padding='valid', dilation_rate=(1, 1), activation=None, use_bias=True)`: 2D transposed convolution layer.\n",
        "    *  `filters`: Integer, the dimension of the output space (the number of filters in the transposed convolution).\n",
        "    *  `kernel_size`: Integer, specifying the size of the transposed convolution window.\n",
        "    *  `strides`: Integer or tuple/list of 1 integer, specifying the stride length of the transposed convolution. `strides > 1` is incompatible with `dilation_rate > 1`.\n",
        "    *  `padding`: one of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to the left/right or up/down of the input. When padding=\"same\" and strides=1, the output has the same size as the input.\n",
        "    *  `dilation`: Integer or tuple/list of 1 integers, specifying the dilation rate to use for dilated transposed convolution.\n",
        "    *  `activation`: Activation function. If None, no activation is applied. Possible values: 'relu', 'sigmoid', 'softmax', etc.\n",
        "    *  `use_bias`: Boolean, whether the layer uses a bias vector.\n",
        "\n",
        "\n",
        "*  `tensorflow.keras.layers.Dense(units, activation=None, use_bias=True)`: Just your regular densely-connected NN layer.\n",
        "    *  `units`: Positive integer, dimensionality of the output space.\n",
        "    *  `activation`: Activation function to use. If you don't specify anything, no activation is applied. Possible values: 'relu', 'selu', 'sigmoid', 'softmax', 'softplus', 'tanh', etc.\n",
        "    *  `use_bias`: Boolean, whether the layer uses a bias vector.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "from tensorflow.keras.layers import Dense\n",
        "Dense(256, activation='relu')\n",
        "\n",
        "```\n",
        "\n",
        "*  `tensorflow.keras.layers.Dropout(rate)`: Applies Dropout to the input.\n",
        "    *  `rate`: Float between 0 and 1. Fraction of the input units to drop.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "from tensorflow.keras.layers import Dropout\n",
        "Dropout(0.5)\n",
        "\n",
        "```\n",
        "\n",
        "*  `tensorflow.keras.layers.Flatten()`: Flattens the input.\n",
        "\n",
        "*  `tensorflow.keras.layers.GlobalAveragePooling2D()`: Global average pooling operation for spatial data.\n",
        "\n",
        "*  `tensorflow.keras.layers.GlobalMaxPool2D()`: Global max pooling operation for spatial data.\n",
        "\n",
        "\n",
        "*  `tensorflow.keras.layers.Input(shape=None)`: Input layer.\n",
        "    *  `units`: Shape of the input data.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "Input(shape=(256, 256, 1))\n",
        "\n",
        "```\n",
        "\n",
        "*  `tensorflow.keras.layers.MaxPool2D()`: Max pooling operation for 2D spatial data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEozBMq3IE07"
      },
      "source": [
        "##### Métodos\n",
        "\n",
        "*  `get_weights()`: Return the values of layer.weights as a list of NumPy arrays.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "filters, biases = layer.get_weights()  # layer with bias\n",
        "filters,  = layer.get_weights()        # layer without bias\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0y3bM2kIFWu"
      },
      "source": [
        "##### Atributos\n",
        "\n",
        "*  `trainable`: Whether the layer should be trained (boolean).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MrhtF9QIHDw"
      },
      "source": [
        "<hr>\n",
        "\n",
        "#### Modelos\n",
        "\n",
        "*  `tensorflow.keras.Model(inputs, outputs)`: A model grouping layers into an object with training/inference features.\n",
        "    * `inputs`: Input tensor(s).\n",
        "    * `outputs`: Output tensor(s).\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "```\n",
        "\n",
        "*  `tensorflow.keras.Sequential()`: Sequential groups a linear stack of layers into model.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "from tensorflow.keras.models import Sequential\n",
        "model = Sequential()\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHpEDzFKIKbd"
      },
      "source": [
        "##### Métodos\n",
        "\n",
        "*  `add(layer)`: Adds a layer instance on top of the layer stack.\n",
        "    *  `layer`: layer instance.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "from tensorflow.keras.layers import Flattern\n",
        "model.add(Flatten())\n",
        "\n",
        "```\n",
        "\n",
        "*  `compile(optimizer='rmsprop', loss=None, loss_weights=None, metrics=None, weighted_metrics=None)`: Configures the model for training.\n",
        "    *  `optimizer`: String (name of optimizer) or optimizer instance. Ver sección \"Optimizadores\".\n",
        "    *  `loss`: Loss function. Possible values: 'mean_squared_error', 'binary_crossentropy', 'categorical_crossentropy', etc. To specify different losses for different outputs of a multi-output model, you could also pass a dictionary.\n",
        "    *  `loss_weights`: Optional list or dictionary specifying scalar coefficients (Python floats) to weight the loss contributions of different model outputs. The loss value that will be minimized by the model will then be the weighted sum of all individual losses, weighted by the `loss_weights` coefficients.\n",
        "    *  `metrics`: List of metrics to be evaluated by the model during training and testing. Typically you will use `metrics=['accuracy']`. To specify different metrics for different outputs of a multi-output model, you could also pass a dictionary, such as `metrics={'a':'accuracy', 'b':['accuracy', 'mse']}`.\n",
        "    *  `weighted_metrics`: List of metrics to be evaluated and weighted by `sample_weight` or `class_weight` during training and testing.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "```\n",
        "\n",
        "*  `evaluate(x=None, y=None, batch_size=None, verbose='auto' steps=None)`: Returns the loss value & metrics values for the model in test mode.\n",
        "    *  `x`: Input data.\n",
        "    *  `y`: Target data.\n",
        "    *  `batch_size`: Integer or None. Number of samples per batch of computation.\n",
        "    *  `verbose`: 'auto', 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = single line.\n",
        "    *  `steps`: Integer or None. Total number of steps (batches of samples) before declaring the evaluation round finished.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "loss, acc = model.evaluate(data_test, steps=10, verbose=2)\n",
        "\n",
        "```\n",
        "\n",
        "*  `fit(x=None, y=None, batch_size=None, epochs=1, verbose='auto', validation_split=0.0, validation_data=None steps_per_epoch=None, validation_steps=None, validation_batch_size=None)`: Trains the model for a fixed number of epochs (dataset iterations).\n",
        "    *  `x`: Input data.\n",
        "    *  `y`: Target data.\n",
        "    *  `batch_size`: Integer or None. Number of samples per gradient update.\n",
        "    *  `epochs`: Integer. Number of epochs to train the model.\n",
        "    *  `verbose`: 'auto', 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
        "    *  `validation_split`: Float between 0 and 1. Fraction of the training data to be used as validation data.\n",
        "    *  `validation_data`: Data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data.\n",
        "    *  `steps_per_epoch`: Integer or None. Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch.\n",
        "    *  `validation_steps`: Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch.\n",
        "    *  `validation_batch_size`: Integer or None. Number of samples per validation batch.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "model.fit(data_train,\n",
        "          epochs=6,   \n",
        "          verbose=2,  \n",
        "          steps_per_epoch=20,\n",
        "          validation_data=data_val,\n",
        "          validation_steps=10)\n",
        "\n",
        "```\n",
        "\n",
        "*  `predict(x, batch_size=None, verbose='auto')`: Generates output predictions for the input samples.\n",
        "    *  `x`: Input samples.\n",
        "    *  `batch_size`: Integer or None. Number of samples per batch.\n",
        "    *  `verbose`: 'auto', 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = single line.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "import numpy as np\n",
        "predictions = model.predict(data_test, verbose=2)\n",
        "print(np.argmax([predictions[0]]), np.max(predictions[0]))\n",
        "\n",
        "```\n",
        "\n",
        "*  `summary()`: Prints a string summary of the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF-XA4t7IQHG"
      },
      "source": [
        "##### Atributos\n",
        "\n",
        "*  `layers`: Layers of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPiOZN56IRwI"
      },
      "source": [
        "<hr>\n",
        "\n",
        "#### Modelos pre-entrenados en TensorFlow\n",
        "\n",
        "*  `tensorflow.keras.applications.DenseNet121(include_top=True,weights='imagenet', input_shape=None)`: Instantiates the Densenet121 architecture.\n",
        "\n",
        "*  `tensorflow.keras.applications.EfficientNetB0(include_top=True,weights='imagenet', input_shape=None)`: Instantiates the EfficientNetB0 architecture.\n",
        "\n",
        "*  `tensorflow.keras.applications.EfficientNetB1(include_top=True,weights='imagenet', input_shape=None)`: Instantiates the EfficientNetB1 architecture.\n",
        "\n",
        "*  `tensorflow.keras.applications.InceptionV3(include_top=True, weights='imagenet', input_shape=None,)`: Instantiates the InceptionV3 architecture.\n",
        "\n",
        "*  `tensorflow.keras.applications.MobileNetV2(include_top=True, weights='imagenet', input_shape=None,)`: Instantiates the MobileNetV2 architecture.\n",
        "\n",
        "*  `tensorflow.keras.applications.ResNet50(include_top=True, weights='imagenet', input_shape=None,)`: Instantiates the ResNet50 architecture.\n",
        "    *  `include_top`: Boolean, whether to include the fully-connected layer at the top, as the last layer of the network.\n",
        "    *  `weights`: One of None (random initialization), imagenet (pre-training on ImageNet), or the path to the weights file to be loaded.\n",
        "    *  `input_shape`: Optional shape tuple, only to be specified if include_top is False.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "model = Model(inputs=[base_model.input], outputs=[predictions])\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcpArNlJISdZ"
      },
      "source": [
        "<hr>\n",
        "\n",
        "#### Optimizadores\n",
        "\n",
        "*  `tensorflow.keras.optimizers.Adam(learning_rate=0.001)`: Optimizer that implements the Adam algorithm.\n",
        "\n",
        "*  `tensorflow.keras.optimizers.experimental.Adadelta(learning_rate=0.001)`: Optimizer that implements the Adadelta algorithm.\n",
        "\n",
        "*  `tensorflow.keras.optimizers.experimental.RMSprop(learning_rate=0.001)`: Optimizer that implements the RMSprop algorithm.\n",
        "\n",
        "*  `tensorflow.keras.optimizers.experimental.SGD(learning_rate=0.01)`: Gradient descent (with momentum) optimizer.\n",
        "    *  `learning_rate`: The learning rate.\n",
        "\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-h70T_fJMz3"
      },
      "source": [
        "<hr>\n",
        "\n",
        "#### Otras operaciones\n",
        "\n",
        "* `tensorflow.keras.backend.flatten(x)`\n",
        "\n",
        "* `tensorflow.keras.backend.mean(x)`\n",
        "\n",
        "* `tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, mode='auto')`:\n",
        "    *  `monitor`: Quantity to be monitored.\n",
        "    *  `patience`: Number of epochs with no improvement after which training will be stopped.\n",
        "    *  `mode`: One of `{\"auto\", \"min\", \"max\"}`. In min mode, training will stop when the quantity monitored has stopped decreasing; in \"max\" mode it will stop when the quantity monitored has stopped increasing; in \"auto\" mode, the direction is automatically inferred from the name of the monitored quantity.\n",
        "\n",
        "* `tensorflow.keras.utils.set_random_seed(seed)`: Sets all random seeds for the program (Python, NumPy, and TensorFlow).\n",
        "    * `seed`: Integer, the random seed to use.\n",
        "\n",
        "*  `tensorflow.keras.utils.to_categorical(y, num_classes)`: Converts a class vector (integers) to binary class matrix.\n",
        "    *  `y`: Array-like with class values to be converted into a matrix (integers from 0 to num_classes - 1).\n",
        "    *  `num_classes`: Total number of classes.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, 5)\n",
        "\n",
        "```\n",
        "\n",
        "*  `sklearn.model_selection.train_test_split(arrays, test_size=None, train_size=None)`: Split arrays or matrices into random train and test subsets.\n",
        "    *  `arrays`: Allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas dataframes.\n",
        "    *  `test_size`: If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split.\n",
        "    *  `train_size`: If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split.\n",
        "\n",
        "```python\n",
        "# EJEMPLO\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, val_data = train_test_split(data, train_size=0.8)\n",
        "\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}